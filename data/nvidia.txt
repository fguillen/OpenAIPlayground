Operator

Good afternoon. My name is David, and I'll be your conference operator today. At this time, I'd like to welcome everyone to Nvidia's second-quarter earnings call. Today's conference is being recorded.

All lines have been placed on mute to prevent any background noise. After the speakers' remarks, there'll be a question-and-answer session. [Operator instructions] Thank you. Simona Jankowski, you may begin your conference.

Simona Jankowski -- Vice President, Investor Relations

Thank you. Good afternoon, everyone, and welcome to Nvidia's conference call for the second quarter of fiscal 2024. With me today from Nvidia are Jensen Huang, president and chief executive officer; and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on Nvidia's investor relations website.

The webcast will be available for replay until the conference call to discuss our financial results for the third quarter of fiscal 2024. The content of today's call is Nvidia's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations.

These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, August 23rd, 2023, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.

During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. And with that, let me turn the call over to Colette.

Colette Kress -- Executive Vice President, Chief Financial Officer

Thanks, Simona. We had an exceptional quarter. Record Q2 revenue of 13.51 billion was up 88% sequentially and up 101% year on year and above our outlook of 11 billion. Let me first start with data center.

Record revenue of 10.32 billion was up 141% sequentially and up 171% year on year. Data center compute revenue nearly tripled year on year driven primarily by accelerating demand for cloud from cloud service providers and large consumer internet companies for our HGX platform, the engine of generative and large language models. Major companies including AWS, Google Cloud, Meta, Microsoft Azure, and Oracle Cloud, as well as a growing number of GPU cloud providers are deploying in-volume HGX systems based on our Hopper and Ampere architecture tensor core GPUs. Networking revenue almost doubled year on year driven by our end-to-end InfiniBand networking platform, the gold standard for AI.

There is tremendous demand for Nvidia accelerated computing and AI platforms. Our supply partners have been exceptional in ramping capacity to support our needs. Our data center supply chain, including HGX, with 35,000 parts and highly complex networking, has been built up over the past decade. We have also developed and qualified additional capacity and suppliers for key steps in the manufacturing process such as co-op packaging.

We expect supply to increase each quarter through next year. By geography, data center growth was strongest in the U.S. as customers direct their capital investments to AI and accelerated computing. China's demand was within the historical range of 20% to 25% of our data center revenue, including compute and networking solutions.

At this time, let me take a moment to address recent reports on the potential for increased regulations on our exports to China. We believe the current regulation is achieving the intended results. Given the strength of demand for our products worldwide, we do not anticipate that additional export restrictions on our data center GPUs, if adopted, would have an immediate material impact to our financial results. However, over the long term, restrictions prohibiting the sale of our data center GPUs to China, if implemented, will result in a permanent loss of an opportunity for the U.S.

industry to compete and lead in one of the world's largest markets. Our cloud service providers drove exceptional strong demand for HGX systems in the quarter as they undertake a generational transition to upgrade their data center infrastructure for the new era of accelerated computing and AI. The NVIDIA HGX platform is culminating of nearly two decades of full-stack innovation across silicon, systems, interconnects, networking, software, and algorithms. Instances powered by the NVIDIA H100 tensor core GPUs are now generally available at AWS, Microsoft Azure, and several GPU cloud providers, with others on the way shortly.

Consumer internet companies also drove the very strong demand. Their investments in data center infrastructure purpose-built for AI are already generating significant returns. For example, Meta recently highlighted that, since launching reels and AI recommendations, have driven a more than 24% increase in time spent on Instagram. Enterprises are also racing to deploy generative AI, driving strong consumption of Nvidia-powered instances in the cloud, as well as demand for on-premise infrastructure.

Whether we serve customers in the cloud or on-prem through partners or direct, their applications can run seamlessly on Nvidia AI Enterprise software with access to our acceleration libraries, pre-trained models, and APIs. We announced a partnership with Snowflake to provide enterprises with accelerated paths to create customized generative AI applications using their own proprietary data, all securely within the Snowflake data cloud. With the NVIDIA NeMo platform for developing large language models, enterprises will be able to make custom LLMs for advanced AI services, including chatbots, search, and summarization right from the Snowflake data cloud. Virtually every industry can benefit from generative AI.

For example, AI co-pilot, such as those just announced by Microsoft, can boost the productivity of over a billion office workers and tens of millions of software engineers. Millions of professionals in legal services, sales, customer support, and education will be available to leverage AI systems trained in their fields. And the co-pilots and assistants are set to create new multi-hundred billion dollars market opportunities for our customers. We are seeing some of the earliest applications of generative AI in marketing, media, and entertainment.

WPP, the world's largest marketing and communication services organization, is developing a content engine using Nvidia Omniverse to enable artists and designers to integrate generative AI into 3D content creation. WPP designers can create images from text prompts while responsibly train generative AI tools and content from Nvidia partners such as Adobe and Getty Images using NVIDIA Picasso, a foundry for custom generative AI models for visual design. Visual content provider Shutterstock is also using NVIDIA Picasso to build tools and services that enable users to create 3D scene backgrounds with the help of generative AI. We partnered with ServiceNow and Accenture to launch the AI Lighthouse program, fast-tracking the development of enterprise AI capabilities.

AI Lighthouse unites the ServiceNow enterprise automation platform and engine with Nvidia accelerated computing and with Accenture consulting and deployment services. We are collaborating also with Hugging Face to simplify the creation of new and custom AI models for enterprises. Hugging Face will offer a new service for enterprises to train and tune advanced AI models powered by NVIDIA DGX Cloud. And just yesterday, VMware and Nvidia announce a major new enterprise offering called VMware Private AI Foundation with Nvidia, a fully integrated platform featuring AI software and accelerated computing from Nvidia, with multi-cloud software for enterprises running VMware.

VMware's hundreds of thousands of enterprise customers will have access to the infrastructure, AI, and cloud management software needed to customize models and run generative AI applications such as intelligent chatbot assistance, search, and summarization. We also announced new NVIDIA AI Enterprise-ready servers featuring the new NVIDIA L40S GPU built for the industry-standard data center server ecosystem and BlueField-3 DPU data center infrastructure processor. L40S is not limited by co-op supply and is shipping to the world's leading server system makers. L40S is a universal data center processor designed for high-volume data center scaling out to accelerate the most compute-intensive applications including AI training and [Inaudible], 3D design and visualization, video processing, and NVIDIA Omniverse industrial digitalization.

NVIDIA AI Enterprise-ready servers are fully optimized for VMware Cloud Foundation and Private AI Foundation. Nearly 100 configurations of NVIDIA AI Enterprise-ready servers will soon be available from the world's leading enterprise IT computing companies including Dell, HPE, and Lenovo. The GH200 Grace Hopper Superchip, which combines our Arm-based Grace CPU with Hopper GPU, entered full production and will be available this quarter in OEM servers. It is also shipping to multiple supercomputing customers including Los Alamos National Labs and the Swiss National Computing Centre.

And Nvidia and SoftBank are collaborating on a platform based on GH200 for generative AI and 5G/6G applications. The second-generation version of our Grace Hopper Superchip with the latest HBM GPU memory will be available in Q2 of calendar 2024. We announced the DGX GH200, a new class of large memory AI supercomputer for giant AI language models, recommender systems, and data analytics. This is the first use of the new NVIDIA NVLink Switch System enabling all of its 256 Grace Hopper superchips to work together as one, a huge jump compared to our prior generation connecting just eight GPUs on NVIDIA Link.

DGX GH200 systems are expected to be available by the end of the year, Google Cloud, Meta, and Microsoft among the first to gain access. Strong networking growth was driven primarily by InfiniBand infrastructure to connect HGX GPU systems. Thanks to its end-to-end optimization and in-network computing capabilities, InfiniBand delivers more than double the performance of traditional Ethernet for AI. For billions-of-dollar AI infrastructures, the value from the increased throughput of InfiniBand is worth hundreds of millions and pays for the network.

In addition, only InfiniBand can scale to hundreds of thousands of GPUs. It is the network of choice for leading AI practitioners. For Ethernet-based cloud data centers that seek to optimize their AI performance, we announced NVIDIA Spectrum-X, an accelerated networking platform designed to optimize Ethernet for AI workloads. Spectrum-X couples the spectrum for the Ethernet switch with the BlueField-3 DPU, achieving 1.5x better overall AI performance and power efficiency versus traditional Ethernet.

BlueField-3 DPU is a major success. It is in qualification with major OEMs and ramping across multiple CSP and consumer internet companies. Now, moving to gaming. Gaming revenue of 2.49 billion was up 11% sequentially and 22% year on year.

Growth was fueled by GeForce RTX 40 series GPUs for laptops and desktops, and customer demand was solid and consistent with seasonality. We believe global end demand has returned to growth after last year's slowdown. We have a large upgrade opportunity ahead of us, just 47% of our installed base have upgraded to RTX, and about 20% of a GPU with an RTX 3060 or higher performance. Laptop GPUs posted strong growth in the key back-to-school season led by RTX 4060 GPUs.

Nvidia's GPU-powered laptops have gained in popularity, and their shipments are now outpacing desktop GPUs in several regions around the world. This is likely to shift the reality of our overall gaming revenue again with Q2 and Q3 as the stronger quarters of the year, reflecting the back-to-school and holiday build schedules for laptops. In desktop, we launched the GeForce RTX 4060 and the GeForce RTX 4060 Ti GPUs, bringing the Ada Lovelace architecture down to price points as low as $299. The ecosystem of RTX and DLSS games continued to expand, 35 new games added to DLSS support including blockbusters such as Diablo 4 and Baldur's Gate 3.

There's now over 330 RTX accelerated games and apps. We are bringing generative AI to games. At Computex, we announced NVIDIA Avatar Cloud Engine [Inaudible] for games, a custom AI model foundry service. Developers can use the service to bring intelligence to nonplayer characters.

It harnesses a number of NVIDIA Omniverse and AI technologies including NeMo Riva and Audio2Face. Now moving to professional visualization. Revenue of 375 million was up 28% sequentially and down 24% year on year. The Ada architecture ramp drove strong growth in Q2, rolling out initially in laptop workstations, with a refresh of desktop workstations coming in Q3.

These will include powerful new RTX systems with up to four NVIDIA RTX 6000 GPUs, providing more than 5,800 teraflops of AI performance and 192 gigabytes of GPU memory. They can be configured with NVIDIA AI Enterprise or NVIDIA Omniverse Enterprise. We also announced three new desktop workstation GPUs based on the Ada generation, the NVIDIA RTX 5000, 4500, and 4000, offering up to 2x the RT core throughput and up to 2x faster AI training performance compared to the previous generation. In addition to traditional workloads such as 3D design and content creation, new workloads and generative AI, large language model development, and data science are expanding the opportunities in pro visualization for our RTX technology.

One of the key themes in Jensen's keynote at SIGGRAPH earlier this month was the convergence of graphics and AI. This is where NVIDIA Omniverse is positioned. Omniverse is OpenUSD data platform. OpenUSD is a universal interchange that is quickly becoming the standard for the 3D world, much like HTML is the universal language for 2D content.

Together, Adobe, Apple, Autodesk, Pixar, and Nvidia formed the Alliance for OpenUSD. Our mission is to accelerate OpenUSD development and adoption. We announced new and upcoming Omniverse Cloud APIs, including RunUSD and ChatUSD to bring generative AI to OpenUSD workloads. Moving to automotive.

Revenue was 253 million, down 15% sequentially and up 15% year on year. Solid year-on-year growth was driven by the ramp of self-driving platforms based on NVIDIA DRIVE Orin SoC with a number of new energy vehicle makers. The sequential decline reflects lower overall automotive demand, particularly in China. We announced a partnership with MediaTek to bring drivers and passengers new experiences inside the car.

MediaTek will develop automotive SoCs and integrate a new product line of NVIDIA GPU chipsets. The partnership covers a wide range of vehicle segments from luxury to entry-level. Moving to the rest of the P&L. GAAP gross margins expanded to 70.1% and non-GAAP gross margin to 71.2% driven by higher data center sales.

Our data center products include a significant amount of software and complexity, which is also helping drive our gross margins. Sequential GAAP operating expenses were up 6%, and non-GAAP operating expenses were up 5%, primarily reflecting increased compensation and benefits. We returned approximately 3.4 billion to shareholders in the form of share repurchases and cash dividends. Our board of directors has just approved an additional 25 billion in stock repurchases to add to our remaining 4 billion of authorization as of the end of Q2.

Let me turn to the outlook for the third quarter of fiscal 2024. Demand for our data center platform for AI is tremendous and broad-based across industries and customers. Our demand visibility extends into next year. Our supply over the next several quarters will continue to ramp as we lower cycle times and work with our supply partners to add capacity.

Additionally, the new L40S GPU will help address the growing demand for many types of workloads from cloud to enterprise. For Q3, total revenue is expected to be 16 billion, plus or minus 2%. We expect sequential growth to be driven largely by data center, with gaming and pro vis also contributing. GAAP and non-GAAP gross margins are expected to be 71.5% and 72.5%, respectively, plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately 2.95 billion and 2 billion, respectively.

GAAP and non-GAAP other income and expenses are expected to be an income of approximately 100 million, excluding gains and losses from nonaffiliated investments. GAAP and non-GAAP tax rates are expected to be 14.5%, plus or minus 1%, excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website. In closing, let me highlight some upcoming events for the financial community.

We will attend the Jefferies Tech Summit on August 30th in Chicago, the Goldman Sachs Tech Conference on September 5th in San Francisco, the Evercore Semiconductor Conference on September 6th, as well as the Citi Tech Conference on September 10th, both in New York, and the BofA Virtual AI Conference on September 11th. Our earnings call to discuss the results of our third quarter of fiscal 2024 is scheduled for Tuesday, November 21st. Operator, we will now open the call for questions. Could you please pull for questions for us? Thank you.
